#implementation of step activation function with gradient Descent
import numpy as np
import matplotlib.pyplot as plt

def step_function(x):
    return np.where(x >= 0, 1, 0)

def gradient_descent_step(x, y, lr, epochs):
    weights = 0  # Initialize weights
    for _ in range(epochs):
        y_pred = step_function(x * weights)  # Predict using step function
        error = y - y_pred  # Calculate the error
        weights += lr * np.sum(error * x)  # Update weights
    return weights

# Data
x = np.array([-2, 1, 0, 1, 2])
y = np.array([0, 0, 1, 1, 1])
lr = 0.1
epochs = 10

# Train the model
final_weights = gradient_descent_step(x, y, lr, epochs)

# Generate predictions using the step function
y_pred = step_function(x * final_weights)



print("Final weights:", final_weights)
